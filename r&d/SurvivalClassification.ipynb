{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib, uuid\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-01 21:16:26,855 - v2.data_transformers.BaseTrsTransformer - INFO - Loading data from Z:/REPORTS/TRS wyciÄ…gi/Basic/ddc/final_all.csv\n",
      "2023-03-01 21:16:33,914 - v2.data_transformers.BaseTrsTransformer - INFO - Employee column being generated...\n",
      "2023-03-01 21:16:33,927 - v2.data_transformers.BaseTrsTransformer - INFO - Decoding polish characters...\n",
      "2023-03-01 21:16:34,121 - v2.data_transformers.BaseTrsTransformer - INFO - Adding unique identifier...\n",
      "2023-03-01 21:16:34,185 - v2.data_transformers.BaseTrsTransformer - INFO - Cleaning technology...\n",
      "2023-03-01 21:16:34,193 - v2.data_transformers.BaseTrsTransformer - INFO - Data processed: shape (60955, 24), columns Index(['no', 'name', 'surname', 'status', 'division', 'grade', 'technology',\n",
      "       'position', 'start date', 'end date', 'office location',\n",
      "       'contract type', 'client', 'current project', 'report_date',\n",
      "       'project status', 'owner', 'source', 'traffic source',\n",
      "       'brand awareness source', 'job family', 'skype,,,', 'employee',\n",
      "       'unique_id'],\n",
      "      dtype='object')\n",
      "2023-03-01 21:16:34,193 - v2.data_transformers.SurvivalAttritionTrsTransformer - INFO - Loaded data shape: (60955, 24)\n",
      "2023-03-01 21:16:34,230 - v2.data_transformers.SurvivalAttritionTrsTransformer - INFO - Using related statuses...Shape (55020, 24)\n",
      "2023-03-01 21:16:34,260 - v2.data_transformers.SurvivalAttritionTrsTransformer - INFO - Creating datetime column...\n",
      "2023-03-01 21:16:34,310 - v2.data_transformers.SurvivalAttritionTrsTransformer - INFO - Creating datetime column...\n",
      "2023-03-01 21:16:34,348 - v2.data_transformers.SurvivalAttritionTrsTransformer - INFO - Using related division...\n",
      "2023-03-01 21:16:36,141 - v2.data_transformers.SurvivalAttritionTrsTransformer - INFO - Changing the family job input due to data inconsistency...\n",
      "2023-03-01 21:16:36,170 - v2.data_transformers.SurvivalAttritionTrsTransformer - INFO - One-hot encoding for columns: ['contract type']\n",
      "2023-03-01 21:16:36,218 - v2.data_transformers.SurvivalAttritionTrsTransformer - INFO - Using related dates...\n",
      "2023-03-01 21:16:36,295 - v2.data_transformers.SurvivalAttritionTrsTransformer - INFO - Calculated probability ratios for columns: ['office location', 'technology', 'mapped_client'] \n",
      "2023-03-01 21:16:36,393 - v2.data_transformers.SurvivalAttritionTrsTransformer - INFO - Removing columns... \n"
     ]
    }
   ],
   "source": [
    "from v2.data_transformers.SurvivalAttritionTrsTransformer import SurvivalAttritionTrsTransformer\n",
    "\n",
    "input_paths = {\n",
    "    'data': '<path_to_file>.csv',\n",
    "    'training': '<path_to_file>.csv',\n",
    "}\n",
    "\n",
    "outputh_paths = {\n",
    "    'general':'<output_file>'\n",
    "}\n",
    "\n",
    "cleanup = False\n",
    "transformer = SurvivalAttritionTrsTransformer(path_to_data=input_paths['data'],\n",
    "                                                 training_data_path=input_paths['training'],\n",
    "                                                 predict=False,\n",
    "                                                 cleanup=False)\n",
    "\n",
    "data = transformer.prepare_data_for_attrition_prediction(min_date='01.01.2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dateutil import relativedelta\n",
    "\n",
    "\n",
    "def calc_2(x, y):\n",
    "    delta = relativedelta.relativedelta(x, y)\n",
    "    return delta.months\n",
    "\n",
    "\n",
    "def calc_month_before_termination(data):\n",
    "    data['months_before_termination'] = ((data['max_date'] - data['report_date_dt']) / np.timedelta64(1, 'M'))\n",
    "    data['months_before_termination'] = data['months_before_termination'].apply(lambda x: round(x))\n",
    "    return data\n",
    "\n",
    "\n",
    "def calc_month_of_work(data):\n",
    "    # todo fix this calculation\n",
    "    data['months_of_work'] = ((data['report_date_dt'] - data['start_date_dt']) / np.timedelta64(1, 'M'))\n",
    "    data['months_of_work'] = data['months_of_work'].apply(lambda x: round(x))\n",
    "    return data\n",
    "\n",
    "\n",
    "def calculate_risk(x):\n",
    "    if x <= 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def set_sample(x, y, intervals: int = 2):\n",
    "    if x == 1:  # always take high risk periods\n",
    "        return True\n",
    "\n",
    "    #     if x == np.nan: # those are mid-periods we shouldn't consider\n",
    "    #         return False\n",
    "\n",
    "    if x == 0:  # low risk periods\n",
    "        if y % intervals == 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "def is_on_bench(x, y):\n",
    "    # x = project, y = client\n",
    "    x = x.lower()\n",
    "    y = y.lower()\n",
    "    if 'bench' in x or 'bench' in y:\n",
    "        return 1\n",
    "    elif 'internal' in y:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def avg_time_per_project(tenure, nth_project):\n",
    "    return tenure / nth_project\n",
    "\n",
    "\n",
    "def set_prob_period(x):\n",
    "    if x < 3:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_tenure(x, y):\n",
    "    months_of_empl = (y - x) / np.timedelta64(1, 'M')\n",
    "    return months_of_empl / 12\n",
    "\n",
    "def is_covid_employment(start_date):\n",
    "    import datetime\n",
    "    covid_start = datetime.datetime.strptime('20-03-2020', '%d-%m-%Y')\n",
    "    covid_end = datetime.datetime.strptime('13-05-2022', '%d-%m-%Y')\n",
    "    if covid_start < start_date < covid_end:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_time_to_event(date_column, event_column):\n",
    "    return (risky[date_column] - risky.groupby(['unique_id', risky[event_column].eq(1).cumsum()])[date_column].transform(\"min\"))/np.timedelta64(1, 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = calc_month_before_termination(data)\n",
    "data = calc_month_of_work(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risky = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risky.drop(['sampling', 'months_of_work', 'diff'], inplace=True, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risky['current project'].astype(str)\n",
    "risky['client'].astype(str)\n",
    "risky['current project'].fillna('No data', inplace=True)\n",
    "risky['client'].fillna('No data', inplace=True)\n",
    "risky['is_on_bench'] = risky.apply(lambda x: is_on_bench(x['current project'], x['client']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risky['tenure'] = risky.apply(lambda x: get_tenure(x['start_date_dt'], x['report_date_dt']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risky['is_covid_employment'] = risky['start_date_dt'].apply(is_covid_employment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "pycharm": {
     "name": "#%% todo one function with dynamic column names\n"
    }
   },
   "outputs": [],
   "source": [
    "risky.sort_values(['unique_id', 'report_date_dt'], inplace=True)\n",
    "risky['was_promoted'] = risky.groupby('unique_id').apply(\n",
    "    lambda group: group['grade'] != group['grade'].shift(1)).tolist()\n",
    "risky['was_promoted'] = risky['was_promoted'].map({True: 1, False: 0})\n",
    "risky.loc[risky.groupby('unique_id').head(1).index, 'was_promoted'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risky['project_changed'] = risky.groupby('unique_id').apply(\n",
    "    lambda group: group['current project'] != group['current project'].shift(1)).tolist()\n",
    "risky['project_changed'] = risky['project_changed'].map({True: 1, False: 0})\n",
    "risky.loc[risky.groupby('unique_id').head(1).index, 'project_changed'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risky['account_changed'] = risky.groupby('unique_id').apply(\n",
    "    lambda group: group['client'] != group['client'].shift(1)).tolist()\n",
    "risky['account_changed'] = risky['account_changed'].map({True: 1, False: 0})\n",
    "risky.loc[risky.groupby('unique_id').head(1).index, 'account_changed'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "risky[\"time_since_promo_in_months\"] = get_time_to_event(date_column='report_date_dt', event_column='was_promoted')\n",
    "risky[\"time_since_project_change_in_months\"] = get_time_to_event(date_column='report_date_dt', event_column='project_changed')\n",
    "risky[\"time_since_account_change_in_months\"] = get_time_to_event(date_column='report_date_dt', event_column='account_changed')\n",
    "risky[\"time_since_bench_in_months\"] = get_time_to_event(date_column='report_date_dt', event_column='is_on_bench')\n",
    "risky[\"time_since_training_in_months\"] = get_time_to_event(date_column='report_date_dt', event_column='has_training')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risky.sort_values(['unique_id', 'report_date_dt'], inplace=True)\n",
    "risky['bench_cumsum'] = risky.groupby(['unique_id'])['is_on_bench'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risky['bench_to_tenure'] = risky.apply(lambda x: (x['bench_cumsum'] / 12) / x['tenure'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risky['nth_project'] = risky.groupby(['unique_id'])[\n",
    "                           'project_changed'].cumsum() + 1  # +1 beacuse it is reflecting the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "risky['avg_time_per_project'] = risky.apply(lambda x : avg_time_per_project(x['tenure'], x['nth_project']), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "risky.drop(['months_before_termination', 'months_of_work', 'grade', 'mapped_source', 'report_date',\n",
    "            'bench_cumsum',\n",
    "            'diff', 'initial_grade', 'max_report_date_all', 'max_date', 'technology', 'start_date_dt',\n",
    "            'report_date_dt', 'Jjob family', 'source', 'status', 'division', 'technology', 'start date',\n",
    "            'office location', 'contract type', 'client', 'current project', 'new_job_family', 'name', 'surname', 'grade', 'last_project', 'last_client', 'mapped_project', 'mapped_client', 'has_training'\n",
    "            'is_on_bench', 'was_promoted', 'project_changed', 'account_changed'], axis=1, inplace=True,\n",
    "           errors='ignore')\n",
    "risky.drop(['has_training', 'is_on_bench'], axis=1, inplace=True,\n",
    "           errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34479, 20)\n",
      "Index(['employee', 'unique_id', 'mapped_grade', 'contract type_Contract',\n",
      "       'contract type_Permanent', 'contract type_Sub-contract', 'left',\n",
      "       'office_location_prob_ratio', 'technology_prob_ratio',\n",
      "       'mapped_client_prob_ratio', 'tenure', 'is_covid_employment',\n",
      "       'time_since_promo_in_months', 'time_since_project_change_in_months',\n",
      "       'time_since_account_change_in_months', 'time_since_bench_in_months',\n",
      "       'time_since_training_in_months', 'bench_to_tenure', 'nth_project',\n",
      "       'avg_time_per_project'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(risky.shape)\n",
    "print(risky.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "data = risky.drop_duplicates(subset=['unique_id'], keep='last')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "idx = data.index\n",
    "emp_mapper = pd.DataFrame({'id': idx,\n",
    "                           'employee': data['employee'],\n",
    "                           'churned': data['left'],\n",
    "                           'tenure': data['tenure']})\n",
    "\n",
    "data.drop(['employee', 'unique_id'], axis=1, inplace=True)\n",
    "\n",
    "emp_mapper.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# VIF to verify m-coli\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "target = data['left']\n",
    "X = data.drop(['left'], axis=1)\n",
    "assert 'left' not in X.columns\n",
    "vif_data[\"feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n",
    "                          for i in range(len(X.columns))]\n",
    "\n",
    "print(vif_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "col_to_pairplot = [\n",
    "    'time_since_promo_in_months',\n",
    "    'time_since_account_change_in_months',\n",
    "    'time_since_bench_in_months',\n",
    "    'time_since_training_in_months',\n",
    "    'bench_to_tenure',\n",
    "    'avg_time_per_project',\n",
    "    'nth_project',\n",
    "    'left'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# sns.pairplot(risky[col_to_pairplot], hue='left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "y = data[['left','tenure']]\n",
    "X = data.drop(['left', 'tenure'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "y['cens'] = y['left'].map({0: False, 1: True})\n",
    "y = y[['cens', 'tenure']].to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "aux = [(e1,e2) for e1,e2 in y]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "y = np.array(aux, dtype=[('left', '?'), ('tenure', '<f8')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MODEL TRAINING"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "random_state = 20\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=random_state, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attached id to model: ff8a154a-7e90-40dc-90e5-c07d8da9344e\n"
     ]
    }
   ],
   "source": [
    "rsf = RandomSurvivalForest(n_estimators=1000,\n",
    "                           min_samples_split=10,\n",
    "                           min_samples_leaf=15,\n",
    "                           n_jobs=-1,\n",
    "                           random_state=random_state)\n",
    "rsf.fit(X_train, y_train)\n",
    "\n",
    "persist = True\n",
    "\n",
    "if persist:\n",
    "    model_id = str(uuid.uuid4())\n",
    "    print(f'Attached id to model: {model_id}')\n",
    "    model_dir = 'models'\n",
    "    file_name = f'{model_dir}/surv_model_{model_id}.joblib'\n",
    "    with open(file_name, 'wb') as file:\n",
    "        joblib.dump(rsf, file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9232945489321007"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "samples = 6\n",
    "\n",
    "pred_sample = X_test[X_test.index == 33372]\n",
    "idx_range = list(range(0,samples))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "idx = pred_sample.index\n",
    "mapping ={}\n",
    "\n",
    "for key, value in zip(idx_range, idx):\n",
    "    mapping[key] = value\n",
    "\n",
    "print(mapping)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "surv = rsf.predict_survival_function(pred_sample, return_array=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# predictions = rsf.predict(X_test)\n",
    "# predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "surv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, s in enumerate(surv):\n",
    "    name = emp_mapper.loc[mapping[i], 'employee']\n",
    "    plt.step(rsf.event_times_, s, where=\"post\", label=str(name))\n",
    "plt.ylabel(\"Survival probability\")\n",
    "plt.xlabel(\"Time in years\")\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rsf.event_times_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(\n",
    "    rsf, X_test, y_test, n_repeats=15, random_state=random_state\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {k: result[k] for k in (\"importances_mean\", \"importances_std\",)},\n",
    "    index=X_test.columns\n",
    ").sort_values(by=\"importances_mean\", ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

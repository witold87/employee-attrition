{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from v2.exceptions.data_exceptions import ValidationException\n",
    "from v2.db.db_helper import get_max_inference_date\n",
    "import datetime\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# import argparse\n",
    "#\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--save_to_db', help='Saving results to postgres', store='store_false')\n",
    "# parser.add_argument('--save_to_file', help='Saving results to file', action='store_true')\n",
    "# parser.add_argument('--show_shap', help='Showing SHAP results', action='store_true')\n",
    "#\n",
    "# arguments = parser.parse_args()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "2023\n"
     ]
    }
   ],
   "source": [
    "today = datetime.date.today()\n",
    "first = today.replace(day=1)\n",
    "last_month = first - datetime.timedelta(days=1)\n",
    "last_month_with_last_day = last_month.strftime(\"%Y-%m-%d\")\n",
    "# inference_day = last_month.day\n",
    "inference_month = last_month.month\n",
    "inference_year = last_month.year\n",
    "\n",
    "print(inference_month)\n",
    "print(inference_year)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#Validate data in DB - do we have such records in DB already?\n",
    "def validate_dates(candidate_date_for_inference):\n",
    "    max_date_from_db = get_max_inference_date()\n",
    "    max_date_dt = datetime.datetime.strptime(max_date_from_db, '%Y-%m-%d')\n",
    "    candidate_date_dt = datetime.datetime.strptime(candidate_date_for_inference, '%Y-%m-%d')\n",
    "    if candidate_date_dt <= max_date_dt:\n",
    "        raise ValidationException(f'Inference with date {candidate_date_for_inference} already exists in DB!')\n",
    "\n",
    "def validate_data(candidate_date_for_inference):\n",
    "    validate_dates(candidate_date_for_inference)\n",
    "\n",
    "validate_data(last_month_with_last_day)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# READ DATA FROM THE DATA CATALOG\n",
    "import json\n",
    "with open('data_catalog.json', 'r') as file:\n",
    "    data_catalog = json.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 10:44:07,161 - v2.data_transformers.BaseTrsTransformer - INFO - Loading data from C:/Users/e-wdpk/Downloads/ddc/full_till_10.2023.xlsx\n",
      "2023-11-27 10:44:24,116 - v2.data_transformers.BaseTrsTransformer - INFO - Employee column being generated...\n",
      "2023-11-27 10:44:24,153 - v2.data_transformers.BaseTrsTransformer - INFO - Decoding polish characters...\n",
      "2023-11-27 10:44:24,633 - v2.data_transformers.BaseTrsTransformer - INFO - Adding unique identifier...\n",
      "2023-11-27 10:44:25,302 - v2.data_transformers.BaseTrsTransformer - INFO - Cleaning technology...\n",
      "2023-11-27 10:44:25,313 - v2.data_transformers.BaseTrsTransformer - INFO - Data processed: shape (75334, 21), columns Index(['name', 'surname', 'status', 'division', 'grade', 'technology',\n",
      "       'job family', 'start date', 'end date', 'office location',\n",
      "       'contract type', 'client', 'current project', 'project status',\n",
      "       'report_date', 'sap id', 'owner', 'line manager', 'unnamed: 0.1',\n",
      "       'employee', 'unique_id'],\n",
      "      dtype='object')\n",
      "2023-11-27 10:44:25,314 - v2.data_transformers.SequenceAttritionTrsTransformerNew - INFO - Loaded data shape: (75334, 21)\n",
      "2023-11-27 10:44:25,362 - v2.data_transformers.SequenceAttritionTrsTransformerNew - INFO - Using related statuses...Shape (68763, 21)\n",
      "2023-11-27 10:44:25,415 - v2.data_transformers.SequenceAttritionTrsTransformerNew - INFO - Creating datetime column...\n",
      "2023-11-27 10:44:25,506 - v2.data_transformers.SequenceAttritionTrsTransformerNew - INFO - Creating datetime column...\n",
      "2023-11-27 10:44:26,527 - v2.data_transformers.SequenceAttritionTrsTransformerNew - INFO - Using related division...\n",
      "2023-11-27 10:44:29,788 - v2.data_transformers.SequenceAttritionTrsTransformerNew - INFO - Changing the family job input due to data inconsistency...\n",
      "2023-11-27 10:44:29,864 - v2.data_transformers.SequenceAttritionTrsTransformerNew - INFO - Using related dates...\n",
      "2023-11-27 10:44:30,041 - v2.data_transformers.SequenceAttritionTrsTransformerNew - INFO - Calculated probability ratios for columns: ['office location', 'technology', 'mapped_client'] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using training data path: data/realized_trainings_till_2023-11-27.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 10:44:31,053 - v2.data_transformers.SequenceAttritionTrsTransformerNew - INFO - Removing columns... \n"
     ]
    }
   ],
   "source": [
    "from v2.data_transformers.SequenceAttritionTrsTransformerNew import SequenceAttritionTrsTransformerNew\n",
    "\n",
    "# 7/8/10 -> 31.#\n",
    "inference_month = '10'\n",
    "inference_year = '2023'\n",
    "last_month_with_last_day = last_month.strftime(\"%Y-%m-%d\")\n",
    "report_date = '2023-10-31'# f'{last_month_with_last_day}'\n",
    "\n",
    "input_paths = {\n",
    "    'pred_data': f'<path_to_file>{inference_month}.{inference_year}.xlsx',\n",
    "    'training': f'<path_to_file>.xlsx'\n",
    "}\n",
    "\n",
    "transformer = SequenceAttritionTrsTransformerNew(path_to_data=input_paths['pred_data'],\n",
    "                                                 training_data_path=input_paths['training'],\n",
    "                                                 predict=False,\n",
    "                                                 cleanup=False)\n",
    "\n",
    "data = transformer.prepare_data_for_attrition_prediction(min_date='01.01.2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "data.drop(['Zlecenie', 'Romania'], axis=1, inplace=True, errors='ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "data['current project'] = data['current project'].str.lower()\n",
    "data['client'] = data['client'].str.lower()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#993 unique\n",
    "current_data = data[data['left'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_month_of_work(data):\n",
    "    # todo fix this calculation\n",
    "    data['months_of_work'] = ((data['report_date_dt'] - data['start_date_dt']) / np.timedelta64(1, 'M'))\n",
    "    data['months_of_work'] = data['months_of_work'].apply(lambda x: round(x))\n",
    "    return data\n",
    "\n",
    "def is_on_bench(x, y):\n",
    "    # x = project, y = client\n",
    "    x = x.lower()\n",
    "    y = y.lower()\n",
    "    if 'bench' in x or 'bench' in y:\n",
    "        return 1\n",
    "    elif 'internal' in y:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def avg_time_per_project(tenure, nth_project):\n",
    "    return tenure / nth_project\n",
    "\n",
    "\n",
    "def set_prob_period(x):\n",
    "    if x < 4:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_tenure(x, y):\n",
    "    months_of_empl = (y - x) / np.timedelta64(1, 'M')\n",
    "    return months_of_empl / 12\n",
    "\n",
    "def is_covid_employment(start_date):\n",
    "    import datetime\n",
    "    covid_start = datetime.datetime.strptime('20-03-2020', '%d-%m-%Y')\n",
    "    covid_end = datetime.datetime.strptime('13-05-2022', '%d-%m-%Y')\n",
    "    if covid_start < start_date < covid_end:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_time_to_event(date_column, event_column):\n",
    "    return (risky[date_column] - risky.groupby(['unique_id', risky[event_column].eq(1).cumsum()])[date_column].transform(\"min\"))/np.timedelta64(1, 'M')\n",
    "\n",
    "def calc_months_till_now(data):\n",
    "    data['months_till_now'] = ((data['max_date'] - data['report_date_dt']) / np.timedelta64(1, 'M'))\n",
    "    data['months_till_now'] = data['months_till_now'].apply(lambda x: round(x))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "current_data['tenure'] = current_data.apply(lambda x: get_tenure(x['start_date_dt'], x['report_date_dt']), axis=1)\n",
    "current_data = calc_months_till_now(current_data)\n",
    "current_data = calc_month_of_work(current_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "current_data['client'] = current_data['client'].replace(' ', np.nan)\n",
    "current_data['current project'] = current_data['current project'].replace(' ', np.nan)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "current_data['client'] = current_data['client'].fillna('bench')\n",
    "current_data['current project'] = current_data['current project'].fillna('bench')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [name, surname, grade, technology, office location, client, current project, sap id, line manager, unnamed: 0.1, employee, unique_id, report_date_dt, start_date_dt, max_date, mapped_grade, left, office_location_prob_ratio, technology_prob_ratio, mapped_client_prob_ratio, SAP ID, has_training, tenure, months_till_now, months_of_work]\nIndex: []\n\n[0 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>surname</th>\n      <th>grade</th>\n      <th>technology</th>\n      <th>office location</th>\n      <th>client</th>\n      <th>current project</th>\n      <th>sap id</th>\n      <th>line manager</th>\n      <th>unnamed: 0.1</th>\n      <th>...</th>\n      <th>mapped_grade</th>\n      <th>left</th>\n      <th>office_location_prob_ratio</th>\n      <th>technology_prob_ratio</th>\n      <th>mapped_client_prob_ratio</th>\n      <th>SAP ID</th>\n      <th>has_training</th>\n      <th>tenure</th>\n      <th>months_till_now</th>\n      <th>months_of_work</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows × 25 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_data[current_data['current project'] == np.nan]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "risky = current_data.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "risky['current project'].astype(str)\n",
    "risky['client'].astype(str)\n",
    "#risky['current project'].fillna('No data', inplace=True)\n",
    "#risky['client'].fillna('No data', inplace=True)\n",
    "risky['is_on_bench'] = risky.apply(lambda x: is_on_bench(x['current project'], x['client']), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "#risky['is_covid_employment'] = risky['start_date_dt'].apply(is_covid_employment)\n",
    "risky.sort_values(['unique_id', 'report_date_dt'], inplace=True)\n",
    "risky['was_promoted'] = risky.groupby('unique_id').apply(\n",
    "    lambda group: group['grade'] != group['grade'].shift(1)).tolist()\n",
    "risky['was_promoted'] = risky['was_promoted'].map({True: 1, False: 0})\n",
    "risky.loc[risky.groupby('unique_id').head(1).index, 'was_promoted'] = 1\n",
    "\n",
    "risky['project_changed'] = risky.groupby('unique_id').apply(\n",
    "    lambda group: group['current project'] != group['current project'].shift(1)).tolist()\n",
    "risky['project_changed'] = risky['project_changed'].map({True: 1, False: 0})\n",
    "risky.loc[risky.groupby('unique_id').head(1).index, 'project_changed'] = 0\n",
    "\n",
    "risky['account_changed'] = risky.groupby('unique_id').apply(\n",
    "    lambda group: group['client'] != group['client'].shift(1)).tolist()\n",
    "risky['account_changed'] = risky['account_changed'].map({True: 1, False: 0})\n",
    "risky.loc[risky.groupby('unique_id').head(1).index, 'account_changed'] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "risky[\"time_since_promo_in_months\"] = get_time_to_event(date_column='report_date_dt', event_column='was_promoted')\n",
    "risky[\"time_since_project_change_in_months\"] = get_time_to_event(date_column='report_date_dt',\n",
    "                                                                 event_column='project_changed')\n",
    "risky[\"time_since_account_change_in_months\"] = get_time_to_event(date_column='report_date_dt',\n",
    "                                                                 event_column='account_changed')\n",
    "risky[\"time_since_bench_in_months\"] = get_time_to_event(date_column='report_date_dt', event_column='is_on_bench')\n",
    "risky[\"time_since_training_in_months\"] = get_time_to_event(date_column='report_date_dt', event_column='has_training')\n",
    "risky.sort_values(['unique_id', 'report_date_dt'], inplace=True)\n",
    "risky['bench_cumsum'] = risky.groupby(['unique_id'])['is_on_bench'].cumsum()\n",
    "risky['bench_to_tenure'] = risky.apply(lambda x: (x['bench_cumsum'] / 12) / x['tenure'], axis=1)\n",
    "risky['nth_project'] = risky.groupby(['unique_id'])[\n",
    "                           'project_changed'].cumsum() + 1  # +1 beacuse it is reflecting the changes.\n",
    "risky['avg_time_per_project'] = risky.apply(lambda x: avg_time_per_project(x['tenure'], x['nth_project']), axis=1)\n",
    "\n",
    "\n",
    "risky['is_prob'] = risky['months_of_work'].apply(set_prob_period)\n",
    "risky = risky[risky['is_prob'] == False]\n",
    "risky.drop(['is_prob'], axis=1, inplace=True)\n",
    "\n",
    "risky.drop(['months_before_termination', 'months_of_work', 'mapped_source', 'report_date', 'bench_cumsum',\n",
    "            'left', 'diff', 'initial_grade', 'max_report_date_all', 'technology', 'start_date_dt',\n",
    "             'Jjob family', 'source', 'status', 'division', 'technology', 'start date',\n",
    "            'office location', 'contract type', 'current project', 'new_job_family', 'name', 'surname', 'last_project', 'last_client', 'mapped_project', 'mapped_client', 'has_training'\n",
    "                                                                                       'is_on_bench', 'was_promoted',\n",
    "            'project_changed', 'account_changed'], axis=1, inplace=True,\n",
    "           errors='ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#risky['is_covid_employment'] = risky['start_date_dt'].apply(is_covid_employment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# MAPPING\n",
    "all_predictions = True\n",
    "if not all_predictions:\n",
    "    account = '<account>'\n",
    "    to_pred_df = risky[(risky['client'] == account) & (risky['report_date_dt'] == report_date)]\n",
    "else:\n",
    "    to_pred_df = risky[risky['report_date_dt'] == report_date]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# FILTERING THE L7\n",
    "to_pred_df = to_pred_df[to_pred_df['grade'] != 'L7']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "to_pred_df = to_pred_df.groupby('employee').last()\n",
    "to_pred_df.reset_index(inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "idx = to_pred_df.index\n",
    "\n",
    "mapping = pd.DataFrame({'employee_idx': idx,\n",
    "                        'account': to_pred_df['client'],\n",
    "                             'grade': to_pred_df['grade'],\n",
    "                             'employee_unique_id': to_pred_df['unique_id'],\n",
    "                             'employee': to_pred_df['employee']})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mapping[mapping['employee'] == 'Witold Pawlak']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "inference_date = to_pred_df['max_date'].head(1)\n",
    "inference_date = inference_date[0].strftime('%Y-%m-%d')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "to_pred_df.drop(['sampling', 'is_on_bench', 'has_training', 'unique_id', 'months_till_now', 'months_of_work', 'mapped_source', 'report_date', 'bench_cumsum',\n",
    "            'stay/left', 'diff', 'initial_grade', 'max_report_date_all', 'max_date', 'technology', 'start_date_dt',\n",
    "            'report_date_dt', 'employee', 'job family', 'source', 'status', 'division', 'technology', 'start date',\n",
    "            'office location', 'contract type', 'client', 'current project', 'new_job_family', 'name','grade', 'surname', 'last_project', 'last_client', 'other', 'sap id'], axis=1, inplace=True,\n",
    "           errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "desired_artifact_id = '8ff1eaa2-0887-4605-b20d-4f1bade5cf85'\n",
    "\n",
    "def load_desired_artifacts(artifact_id: str):\n",
    "    with open(f'artifacts/{artifact_id}/models/model.joblib', 'rb') as file:\n",
    "        model = joblib.load(file)\n",
    "\n",
    "    training_data = pd.read_csv(f'artifacts/{artifact_id}/data/training_data.csv', sep=';')\n",
    "    return model, training_data\n",
    "\n",
    "model, training_data = load_desired_artifacts(desired_artifact_id)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "training_columns = training_data.columns\n",
    "to_pred_df = to_pred_df[training_columns]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "assert to_pred_df.shape[1] == training_data.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "predictions = model.predict(to_pred_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "probalities = model.predict_proba(to_pred_df)[:, 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def get_risk_bucket(x):\n",
    "    if x <= 0.5:\n",
    "        return 'no risk'\n",
    "    elif x <= 0.7:\n",
    "        return 'low risk'\n",
    "    elif x <= 0.8:\n",
    "        return 'moderate risk'\n",
    "    elif x <= 0.9:\n",
    "        return 'high risk'\n",
    "    else:\n",
    "        return 'very high risk'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'employee': mapping['employee'],\n",
    "                        'account': mapping['account'],\n",
    "                        'grade': mapping['grade'],\n",
    "                        'inference_date': inference_date,\n",
    "                        'at_risk': predictions,\n",
    "                        'probability': probalities})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "results['risk_bucket'] = results['probability'].apply(get_risk_bucket)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# from model_explainers.lime_explainer import setup_explainer_on_train_data, prepare_contributors_for_prediction\n",
    "#\n",
    "# lime_explainer = setup_explainer_on_train_data(training_data)\n",
    "# contributors = pd.concat(prepare_contributors_for_prediction(to_pred_df, model, explainer=lime_explainer), axis=0, ignore_index=True)\n",
    "# contributors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def get_dynamic_columns_mapping(columns) -> dict:\n",
    "    mapping = {}\n",
    "\n",
    "    for i in range(len(columns)):\n",
    "        mapping[i] = columns[i]\n",
    "\n",
    "    return mapping"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import shap\n",
    "#shap.initjs()\n",
    "from tqdm import tqdm\n",
    "\n",
    "#shap_values = explainer.shap_values(to_pred_df)\n",
    "\n",
    "columns_mapper = get_dynamic_columns_mapping(to_pred_df.columns)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "def get_contributors_with_shap(explainer, prediction_data):\n",
    "    all_contributors = []\n",
    "    n_predictions = prediction_data.shape[0]\n",
    "    shap_values = explainer(to_pred_df)\n",
    "    for i in tqdm(range(n_predictions)):\n",
    "        impact_values = pd.DataFrame(shap_values[i].values)\n",
    "        impact_df = impact_values.T\n",
    "        impact_df = impact_df.rename(columns=columns_mapper)\n",
    "        all_contributors.append(impact_df)\n",
    "\n",
    "    return all_contributors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1094/1094 [00:01<00:00, 672.40it/s]\n"
     ]
    }
   ],
   "source": [
    "contributors_shap = pd.concat(get_contributors_with_shap(explainer, to_pred_df), axis=0, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "pred_and_impact_df = pd.concat([results, contributors_shap], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "time_since_bench_in_months    0.110895\ntime_since_promo_in_months    0.110050\navg_time_per_project          0.108647\nnth_project                   0.105253\nmapped_client_prob_ratio      0.102784\ndtype: float32"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importances = pd.Series(model.feature_importances_, index=training_data.columns)\n",
    "feat_importances.sort_values(ascending=False).head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# import shap\n",
    "# shap.initjs()\n",
    "# explainer = shap.TreeExplainer(model)\n",
    "# #shap_values = explainer.shap_values(to_pred_df)\n",
    "# shap_values = explainer(to_pred_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "#shap.summary_plot(shap_values) # wez ten wykres, jest super\n",
    "#shap.plots.beeswarm(shap_values) # wez ten wykres, jest super\n",
    "#shap.waterfall_plot(shap_values[1108])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def check_if_file_exists(path_to_file):\n",
    "    return os.path.exists(path_to_file)\n",
    "\n",
    "save_to_file = False\n",
    "\n",
    "if save_to_file:\n",
    "    file_name = ''\n",
    "\n",
    "    if not all_predictions:\n",
    "        file_name = f'{account}_predictions_{report_date}.xlsx'\n",
    "    else:\n",
    "        file_name = f'all_predictions_grade_{report_date}.xlsx'\n",
    "\n",
    "    if check_if_file_exists(file_name):\n",
    "        print(f'File {file_name} exists, opening...')\n",
    "        existing_predictions_df = pd.read_excel(file_name)\n",
    "        print(f'Pre shape: {existing_predictions_df.shape}')\n",
    "        print(f'Pre shape results: {results.shape}')\n",
    "        all = pd.concat([existing_predictions_df, results], axis=0)\n",
    "        print(f'Post shape: {all.shape}')\n",
    "        all.to_excel(file_name)\n",
    "    else:\n",
    "        results.to_excel(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "from v2.db.db_helper import connect_to_db\n",
    "engine = connect_to_db()\n",
    "schema = 'public'\n",
    "table = 'predictions_with_explainers'\n",
    "pred_and_impact_df.to_sql(f'{table}', con=engine, if_exists='append', schema=f'{schema}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
